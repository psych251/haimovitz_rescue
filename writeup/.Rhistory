### dataframe without the open response questions
survey_responses <- filtered_pilot %>%
select(-Open_1, -Open_2, -Open_3)
write.csv(survey_responses, "/Users/khaingmon/Desktop/haimovitz_rescue/data/final_survey_responses.csv")
View(survey_responses)
#load in the coded data your_data <- read.csv("/Users/khaingmon/Desktop/haimovitz_rescue/data/check.csv", fill = TRUE)
coded_data <- read.csv("/Users/khaingmon/Desktop/haimovitz_rescue/data/final_coded_responses.csv", header = TRUE, sep = ",")
enhancing_count <- nrow(subset(survey_responses, Condition == "Enhancing"))
debilitating_count <- nrow(subset(survey_responses, Condition == "Debilitating"))
enhancing_count
debilitating_count
ICC_p<- read.csv("/Users/khaingmon/Desktop/haimovitz_rescue/data/ICC_performance.csv", header = TRUE, sep = ",")
ICC_l<- read.csv("/Users/khaingmon/Desktop/haimovitz_rescue/data/ICC_learning.csv", header = TRUE, sep = ",")
# calculate the ICC score for performance
ICC_p_coder1 <- data.frame(Coder_1 = rowSums(subset(ICC_p, Coder == 1)[, 3:8]))
ICC_p_coder2 <- data.frame(Coder_1 = rowSums(subset(ICC_p, Coder == 2)[, 3:8]))
ICC_p_data<- data.frame(Coder1 = ICC_p_coder1, Coder2 = ICC_p_coder2)
colnames(ICC_p_data) <- c("Coder1", "Coder2")
ICC_performance <-icc(ICC_p_data, model = "twoway", type = "consistency")
# calculate the ICC score for performance
ICC_l_coder1 <- data.frame(Coder_1 = rowSums(subset(ICC_l, Coder == 1)[, 3:8]))
ICC_l_coder2 <- data.frame(Coder_1 = rowSums(subset(ICC_l, Coder == 2)[, 3:8]))
ICC_l_data<- data.frame(Coder1 = ICC_l_coder1, Coder2 = ICC_l_coder2)
colnames(ICC_l_data) <- c("Coder1", "Coder2")
ICC_learning <-icc(ICC_l_data, model = "twoway", type = "consistency")
#print results
ICC_performance
ICC_learning
# change survey answers into numeric values
columns_to_transform <- c("Initial.Survey_1","Initial.Survey_2","Initial.Survey_3","Initial.Survey_4", "Enhancing_1","Enhancing_2","Enhancing_3","Enhancing_4","Enhancing_5", "Debilitating_1", "Debilitating_2" , "Debilitating_3", "Debilitating_4", "Debilitating_5", "Closing_1", "Closing_2", "Closing_3", "Closing_4", "Closing_5", "Closing_6")
survey_responses <- survey_responses %>%
mutate_at(vars(columns_to_transform), ~as.numeric(sub("\\s*\\((.*?)\\)\\s*", "", .)))
# divide the dataset into the enhancing condition and get the means for questionnaire
enhancing_data <- subset(survey_responses, Condition == "Enhancing")
enhancing_cols <- enhancing_data[, c("Enhancing_1", "Enhancing_2", "Enhancing_3", "Enhancing_4", "Enhancing_5")]
mean_enhancing <- rowMeans(enhancing_cols)
manipulationcheck1_enhancing <- t.test(mean_enhancing, mu = 3.5, alternative = "greater")
# divide the dataset into the enhancing condition and get the means for questionnaire
debilitating_data <- subset(survey_responses, Condition == "Debilitating")
debilitating_cols <- debilitating_data[, c("Debilitating_1", "Debilitating_2", "Debilitating_3", "Debilitating_4", "Debilitating_5")]
mean_debilitating <- rowMeans(debilitating_cols)
manipulationcheck1_debilitating <- t.test(mean_debilitating, mu = 3.5, alternative = "greater")
manipulationcheck1_enhancing
manipulationcheck1_debilitating
manipulationcheck2 <- t.test(mean_enhancing, mean_debilitating, alternative = "two.sided", var.equal = FALSE)
manipulationcheck2
# Note: when parents stated disappointment or anger, I tally in the pity category.
enhancing_coded <- survey_responses %>%
filter(Condition == "Enhancing")
debilitating_coded <- survey_responses %>%
filter(Condition == "Debilitating")
#for the presentation, since we only coded up 20 participants, we will just do t-test on those
coded_data_20 = coded_data[1:20, ]
#separate coded data into FIE/FID conditions
coded_fie <- coded_data_20 %>%
filter(Condition == 'Enhancing')
coded_fid <- coded_data_20 %>%
filter(Condition == 'Debilitating')
#conduct the t-test.
t_test_performance <- t.test(coded_fie$sum_performance, coded_fid$sum_performance, alternative = "two.sided", var.equal = FALSE)
t_test_learning <- t.test(coded_fie$sum_learning, coded_fid$sum_learning, alternative = "two.sided", var.equal = FALSE)
#calculate standard errors for performance vs. learning
SEI_performance <- t_test_performance$stderr
SEI_learning <- t_test_learning$stderr
graph <- coded_data %>%
pivot_longer(sum_performance:sum_learning,
names_to = "response_type",
values_to = "num_response") %>%
group_by(Condition, response_type) %>%
summarise(
count = n(),
mean = mean(num_response, na.rm = TRUE),
sd = sd(num_response, na.rm = TRUE),
sem = sd / sqrt(count)
)
# reorder the graph so that performance comes before learning
graph$response_type <- factor(graph$response_type, levels = c("sum_performance", "sum_learning"))
ggplot(data = graph, aes(x = response_type, y = mean, fill = Condition)) +
geom_bar(stat = "identity", position = "dodge", width = 0.7, colour="black") +
geom_errorbar(aes(ymin = mean - sem, ymax = mean + sem), position = position_dodge(width = 0.7), width = 0.25) +
labs(title = "Parental Responses to Child-Failure Scenario",
x = "",
y = "Number of Responses",
fill = "",) +
scale_fill_manual(values = c("Debilitating" = "white", "Enhancing" = "darkgrey"), #rename labels and dedicate colors to conditoins
name = "Condition",
labels = c("Debilitating" = "Failure-is-Debilitating Condition", "Enhancing" = "Failure-is-Enhancing Condition")) +
scale_x_discrete(labels = c("sum_performance" = "Performance-Oriented", "sum_learning" = "Learning-Oriented")) +
scale_y_continuous(expand = c(0, 0)) + # plot starts at bottom of y-axis
theme_minimal() +
theme( # change theme to be more similar to original paper
panel.grid = element_blank(),
panel.border = element_blank(),
axis.line = element_line(color = "black"),
)
# Gender
gender_counts <- table(survey_responses$Gender)
print(gender_counts)
ggplot(survey_responses, aes(x = Gender, fill = Gender)) +
geom_bar(color = "black", position = "identity") +
theme_minimal() +
labs(title = "Demographics: Gender",
x = "Identified Gender",
y = "Count") +
theme_minimal() +
theme(
panel.grid = element_blank(),
panel.border = element_blank(),
axis.text.x = element_blank(),  #gets rid of long labels
axis.line = element_line(color = "black"), #added y-axis line
plot.title = element_text(hjust = 0.5)  # Center the title
)
# run meta-analysis using RMA
paper_names <- c("Original Paper", "My Rescue Paper")
performance_effect_sizes <- c(0.075, cohen.d(coded_fie$sum_performance, coded_fid$sum_performance)$estimate)
learning_effect_sizes <- c(0.031, cohen.d(coded_fie$sum_learning, coded_fid$sum_learning)$estimate)
# As I have no standard errors of the original paper, I used mine for both
metadata <- data.frame(paper = paper_names,
performance_effect_size = performance_effect_sizes,
learning_effect_size = learning_effect_sizes,
SEI_performance = SEI_performance,
SEI_learning = SEI_performance)
performance_model <- rma(yi = performance_effect_size, sei = SEI_performance, data = metadata)
learning_model <- rma(yi = learning_effect_size,sei = SEI_learning, data = metadata)
forest(performance_model, slab = paper_names)
forest(learning_model, slab = paper_names)
#load in the coded data your_data <- read.csv("/Users/khaingmon/Desktop/haimovitz_rescue/data/check.csv", fill = TRUE)
coded_data <- read.csv("/Users/khaingmon/Desktop/haimovitz_rescue/data/final_coded_responses.csv", header = TRUE, sep = ",")
enhancing_count <- nrow(subset(survey_responses, Condition == "Enhancing"))
debilitating_count <- nrow(subset(survey_responses, Condition == "Debilitating"))
"The number of subjects in the failure-is-enhancing condition are:" enhancing_count
#load in the coded data your_data <- read.csv("/Users/khaingmon/Desktop/haimovitz_rescue/data/check.csv", fill = TRUE)
coded_data <- read.csv("/Users/khaingmon/Desktop/haimovitz_rescue/data/final_coded_responses.csv", header = TRUE, sep = ",")
enhancing_count <- nrow(subset(survey_responses, Condition == "Enhancing"))
debilitating_count <- nrow(subset(survey_responses, Condition == "Debilitating"))
cat("The number of subjects in the failure-is-enhancing condition are:", enhancing_count)
debilitating_count
#load in the coded data your_data <- read.csv("/Users/khaingmon/Desktop/haimovitz_rescue/data/check.csv", fill = TRUE)
coded_data <- read.csv("/Users/khaingmon/Desktop/haimovitz_rescue/data/final_coded_responses.csv", header = TRUE, sep = ",")
enhancing_count <- nrow(subset(survey_responses, Condition == "Enhancing"))
debilitating_count <- nrow(subset(survey_responses, Condition == "Debilitating"))
cat("The number of subjects in the failure-is-enhancing condition are:", enhancing_count)
cat("The number of subjects in the failure-is-debilitating condition are:", debilitating_count)
#load in the coded data your_data <- read.csv("/Users/khaingmon/Desktop/haimovitz_rescue/data/check.csv", fill = TRUE)
coded_data <- read.csv("/Users/khaingmon/Desktop/haimovitz_rescue/data/final_coded_responses.csv", header = TRUE, sep = ",")
enhancing_count <- nrow(subset(survey_responses, Condition == "Enhancing"))
debilitating_count <- nrow(subset(survey_responses, Condition == "Debilitating"))
cat("The number of subjects in the failure-is-enhancing condition are:", enhancing_count)
cat("The number of subjects in the failure-is-debilitating condition are:", debilitating_count)
#### Load Relevant Libraries and Functions
library(tidyverse)
library(knitr)
library(effsize)
library(irr)
library(metafor)
#### Import Final Qualtrics Data as CSV File
setwd("/Users/khaingmon/Desktop/Psych_251_Data/")
final_data <- read.csv("FinalData.csv", header = TRUE, sep = ",")
#### Exclude Columns to Anonymize Respondents and remove all Pilot/Testing Data
final_data <- final_data[-c(1:29), ]
final_data <- final_data[, -c(3:8)]
final_data <- final_data[, -c(4:11)]
final_data <- final_data[, -c(1:2)]
#### Load Relevant Libraries and Functions
library(tidyverse)
library(knitr)
library(effsize)
library(irr)
library(metafor)
#### Import Final Qualtrics Data as CSV File
setwd("/Users/khaingmon/Desktop/Psych_251_Data/")
final_data <- read.csv("FinalData.csv", header = TRUE, sep = ",")
#### Exclude Columns to Anonymize Respondents and remove all Pilot/Testing Data
final_data <- final_data[-c(1:29), ]
final_data <- final_data[, -c(3:8)]
final_data <- final_data[, -c(4:11)]
final_data <- final_data[, -c(1:2)]
columns_to_transform <- c("Initial.Survey_1", "Initial.Survey_2", "Initial.Survey_3", "Initial.Survey_4", "Enhancing_1", "Enhancing_2", "Enhancing_3", "Enhancing_4", "Enhancing_5", "Debilitating_1", "Debilitating_2", "Debilitating_3", "Debilitating_4", "Debilitating_5", "Closing_1", "Closing_2", "Closing_3", "Closing_4", "Closing_5", "Closing_6")
survey_responses <- survey_responses %>%
mutate(across(all_of(columns_to_transform), ~as.numeric(sub("\\s*\\((.*?)\\)\\s*", "", .))))
### Enhancing Condition: Divide the Dataset into the relevant condition and calculate the mean for each row of responses
enhancing_data <- subset(survey_responses, Condition == "Enhancing")
enhancing_cols <- enhancing_data[, c("Enhancing_1", "Enhancing_2", "Enhancing_3", "Enhancing_4", "Enhancing_5")]
mean_enhancing <- rowMeans(enhancing_cols)
manipulationcheck1_enhancing <- t.test(mean_enhancing, mu = 3.5, alternative = "greater")
### Debilitating Condition: Divide the Dataset into the relevant condition and calculate the mean for each row of responses
debilitating_data <- subset(survey_responses, Condition == "Debilitating")
debilitating_cols <- debilitating_data[, c("Debilitating_1", "Debilitating_2", "Debilitating_3", "Debilitating_4", "Debilitating_5")]
mean_debilitating <- rowMeans(debilitating_cols)
manipulationcheck1_debilitating <- t.test(mean_debilitating, mu = 3.5, alternative = "greater")
manipulationcheck1_enhancing
manipulationcheck1_debilitating
# Note: when parents stated disappointment or anger, I tally in the pity category.
enhancing_coded <- survey_responses %>%
filter(Condition == "Enhancing")
debilitating_coded <- survey_responses %>%
filter(Condition == "Debilitating")
#for the presentation, since we only coded up 20 participants, we will just do t-test on those
coded_data_20 = coded_data[1:20, ]
#separate coded data into FIE/FID conditions
coded_fie <- coded_data_20 %>%
filter(Condition == 'Enhancing')
coded_fid <- coded_data_20 %>%
filter(Condition == 'Debilitating')
#conduct the t-test.
t_test_performance <- t.test(coded_fie$sum_performance, coded_fid$sum_performance, alternative = "two.sided", var.equal = FALSE)
t_test_learning <- t.test(coded_fie$sum_learning, coded_fid$sum_learning, alternative = "two.sided", var.equal = FALSE)
#calculate standard errors for performance vs. learning
SEI_performance <- t_test_performance$stderr
SEI_learning <- t_test_learning$stderr
View(enhancing_coded)
View(enhancing_cols)
head(coded_data)
#for the presentation, since we only coded up 20 participants, we will just do t-test on those
coded_data_20 = coded_data[1:20, ]
#separate coded data into FIE/FID conditions
coded_fie <- coded_data_20 %>%
filter(Condition == 'Enhancing')
coded_fid <- coded_data_20 %>%
filter(Condition == 'Debilitating')
#conduct the t-test.
t_test_performance <- t.test(coded_fie$sum_performance, coded_fid$sum_performance, alternative = "two.sided", var.equal = FALSE)
t_test_learning <- t.test(coded_fie$sum_learning, coded_fid$sum_learning, alternative = "two.sided", var.equal = FALSE)
#calculate standard errors for performance vs. learning
SEI_performance <- t_test_performance$stderr
SEI_learning <- t_test_learning$stderr
View(coded_fid)
View(coded_fie)
### Imported Coded Open Responses
coded_data <- read.csv("/Users/khaingmon/Desktop/haimovitz_rescue/data/final_coded_responses.csv", header = TRUE, sep = ",")
### Separate Coded Data into the two manipulation conditions
coded_fie <- coded_data %>%
filter(Condition == 'Enhancing')
coded_fid <- coded_data %>%
filter(Condition == 'Debilitating')
#conduct the t-test.
t_test_performance <- t.test(coded_fie$sum_performance, coded_fid$sum_performance, alternative = "two.sided", var.equal = FALSE)
t_test_learning <- t.test(coded_fie$sum_learning, coded_fid$sum_learning, alternative = "two.sided", var.equal = FALSE)
#calculate standard errors for performance vs. learning
SEI_performance <- t_test_performance$stderr
SEI_learning <- t_test_learning$stderr
View(coded_fie)
View(coded_fid)
### Imported Coded Open Responses
coded_data <- read.csv("/Users/khaingmon/Desktop/haimovitz_rescue/data/final_coded_responses.csv", header = TRUE, sep = ",")
### Separate Coded Data into the two manipulation conditions
coded_fie <- coded_data %>%
filter(Condition == 'Enhancing')
coded_fid <- coded_data %>%
filter(Condition == 'Debilitating')
# Conduct the T-Test
t_test_performance <- t.test(coded_fie$sum_performance, coded_fid$sum_performance, alternative = "two.sided", var.equal = FALSE)
t_test_performance
t_test_learning <- t.test(coded_fie$sum_learning, coded_fid$sum_learning, alternative = "two.sided", var.equal = FALSE)
t_test_performance
#calculate standard errors for performance vs. learning
SEI_performance <- t_test_performance$stderr
SEI_learning <- t_test_learning$stderr
graph <- coded_data %>%
pivot_longer(sum_performance:sum_learning,
names_to = "response_type",
values_to = "num_response") %>%
group_by(Condition, response_type) %>%
summarise(
count = n(),
mean = mean(num_response, na.rm = TRUE),
sd = sd(num_response, na.rm = TRUE),
sem = sd / sqrt(count)
)
# reorder the graph so that performance comes before learning
graph$response_type <- factor(graph$response_type, levels = c("sum_performance", "sum_learning"))
ggplot(data = graph, aes(x = response_type, y = mean, fill = Condition)) +
geom_bar(stat = "identity", position = "dodge", width = 0.7, colour="black") +
geom_errorbar(aes(ymin = mean - sem, ymax = mean + sem), position = position_dodge(width = 0.7), width = 0.25) +
labs(title = "Parental Responses to Child-Failure Scenario",
x = "",
y = "Number of Responses",
fill = "",) +
scale_fill_manual(values = c("Debilitating" = "white", "Enhancing" = "darkgrey"), #rename labels and dedicate colors to conditoins
name = "Condition",
labels = c("Debilitating" = "Failure-is-Debilitating Condition", "Enhancing" = "Failure-is-Enhancing Condition")) +
scale_x_discrete(labels = c("sum_performance" = "Performance-Oriented", "sum_learning" = "Learning-Oriented")) +
scale_y_continuous(expand = c(0, 0)) + # plot starts at bottom of y-axis
theme_minimal() +
theme( # change theme to be more similar to original paper
panel.grid = element_blank(),
panel.border = element_blank(),
axis.line = element_line(color = "black"),
)
### Imported Coded Open Responses
coded_data <- read.csv("/Users/khaingmon/Desktop/haimovitz_rescue/data/final_coded_responses.csv", header = TRUE, sep = ",")
### Separate Coded Data into the two manipulation conditions
coded_fie <- coded_data %>%
filter(Condition == 'Enhancing')
coded_fid <- coded_data %>%
filter(Condition == 'Debilitating')
# Conduct the T-Test
t_test_performance <- t.test(coded_fie$sum_performance, coded_fid$sum_performance, alternative = "two.sided", var.equal = FALSE)
t_test_performance
t_test_learning <- t.test(coded_fie$sum_learning, coded_fid$sum_learning, alternative = "two.sided", var.equal = FALSE)
t_test_learning
#calculate standard errors for performance vs. learning
SEI_performance <- t_test_performance$stderr
SEI_learning <- t_test_learning$stderr
graph <- coded_data %>%
pivot_longer(sum_performance:sum_learning,
names_to = "response_type",
values_to = "num_response") %>%
group_by(Condition, response_type, .groups = "drop") %>%
summarise(
count = n(),
mean = mean(num_response, na.rm = TRUE),
sd = sd(num_response, na.rm = TRUE),
sem = sd / sqrt(count)
)
# reorder the graph so that performance comes before learning
graph$response_type <- factor(graph$response_type, levels = c("sum_performance", "sum_learning"))
ggplot(data = graph, aes(x = response_type, y = mean, fill = Condition)) +
geom_bar(stat = "identity", position = "dodge", width = 0.7, colour="black") +
geom_errorbar(aes(ymin = mean - sem, ymax = mean + sem), position = position_dodge(width = 0.7), width = 0.25) +
labs(title = "Parental Responses to Child-Failure Scenario",
x = "",
y = "Number of Responses",
fill = "",) +
scale_fill_manual(values = c("Debilitating" = "white", "Enhancing" = "darkgrey"), #rename labels and dedicate colors to conditoins
name = "Condition",
labels = c("Debilitating" = "Failure-is-Debilitating Condition", "Enhancing" = "Failure-is-Enhancing Condition")) +
scale_x_discrete(labels = c("sum_performance" = "Performance-Oriented", "sum_learning" = "Learning-Oriented")) +
scale_y_continuous(expand = c(0, 0)) + # plot starts at bottom of y-axis
theme_minimal() +
theme( # change theme to be more similar to original paper
panel.grid = element_blank(),
panel.border = element_blank(),
axis.line = element_line(color = "black"),
)
graph <- coded_data %>%
pivot_longer(sum_performance:sum_learning,
names_to = "response_type",
values_to = "num_response") %>%
group_by(Condition, response_type, .groups = "drop") %>%
summarise(
count = n(),
mean = mean(num_response, na.rm = TRUE),
sd = sd(num_response, na.rm = TRUE),
sem = sd / sqrt(count)
)
### Reorder the bars so that performance comes before learning
graph$response_type <- factor(graph$response_type, levels = c("sum_performance", "sum_learning"))
ggplot(data = graph, aes(x = response_type, y = mean, fill = Condition)) +
geom_bar(stat = "identity", position = "dodge", width = 0.7, colour="black") +
geom_errorbar(aes(ymin = mean - sem, ymax = mean + sem), position = position_dodge(width = 0.7), width = 0.25) +
labs(title = "Parental Responses to Child-Failure Scenario",
x = "",
y = "Number of Responses",
fill = "",) +
scale_fill_manual(values = c("Debilitating" = "white", "Enhancing" = "darkgrey"), #rename labels and dedicate colors to conditoins
name = "Condition",
labels = c("Debilitating" = "Failure-is-Debilitating Condition", "Enhancing" = "Failure-is-Enhancing Condition")) +
scale_x_discrete(labels = c("sum_performance" = "Performance-Oriented", "sum_learning" = "Learning-Oriented")) +
scale_y_continuous(expand = c(0, 0)) + # plot starts at bottom of y-axis
theme_minimal() +
theme( # change theme to be more similar to original paper
panel.grid = element_blank(),
panel.border = element_blank(),
axis.line = element_line(color = "black"),
)
graph <- coded_data %>%
pivot_longer(sum_performance:sum_learning,
names_to = "response_type",
values_to = "num_response") %>%
group_by(Condition, response_type, .groups = "drop") %>%
summarise(
count = n(),
mean = mean(num_response, na.rm = TRUE),
sd = sd(num_response, na.rm = TRUE),
sem = sd / sqrt(count)
)
### Reorder the bars so that performance comes before learning
graph$response_type <- factor(graph$response_type, levels = c("sum_performance", "sum_learning"))
ggplot(data = graph, aes(x = response_type, y = mean, fill = Condition)) +
geom_bar(stat = "identity", position = "dodge", width = 0.7, colour="black") +
geom_errorbar(aes(ymin = mean - sem, ymax = mean + sem), position = position_dodge(width = 0.7), width = 0.25) +
labs(title = "Parental Responses to Child-Failure Scenario",
x = "",
y = "Number of Responses",
fill = "",) +
scale_fill_manual(values = c("Debilitating" = "white", "Enhancing" = "darkgrey"), #rename labels and dedicate colors to conditoins
name = "Condition",
labels = c("Debilitating" = "Failure-is-Debilitating Condition", "Enhancing" = "Failure-is-Enhancing Condition")) +
scale_x_discrete(labels = c("sum_performance" = "Performance-Oriented", "sum_learning" = "Learning-Oriented")) +
scale_y_continuous(expand = c(0, 0)) + # plot starts at bottom of y-axis
theme_minimal() +
theme( # change theme to be more similar to original paper
panel.grid = element_blank(),
panel.border = element_blank(),
axis.line = element_line(color = "black"),
)
### run meta-analysis using RMA
paper_names <- c("Original Paper", "My Rescue Paper")
performance_effect_sizes <- c(0.075, cohen.d(coded_fie$sum_performance, coded_fid$sum_performance)$estimate)
learning_effect_sizes <- c(0.031, cohen.d(coded_fie$sum_learning, coded_fid$sum_learning)$estimate)
### Since I have no standard errors of the original paper, I used mine for both
metadata <- data.frame(paper = paper_names,
performance_effect_size = performance_effect_sizes,
learning_effect_size = learning_effect_sizes,
SEI_performance = SEI_performance,
SEI_learning = SEI_performance)
### Run RMA
performance_model <- rma(yi = performance_effect_size, sei = SEI_performance, data = metadata)
learning_model <- rma(yi = learning_effect_size,sei = SEI_learning, data = metadata)
### Plot Forest
forest(performance_model, slab = paper_names)
forest(learning_model, slab = paper_names)
graph <- coded_data %>%
pivot_longer(sum_performance:sum_learning,
names_to = "response_type",
values_to = "num_response") %>%
group_by(Condition, response_type) %>%
summarise(
count = n(),
mean = mean(num_response, na.rm = TRUE),
sd = sd(num_response, na.rm = TRUE),
sem = sd / sqrt(count),
.groups = "drop"
)
### Reorder the bars so that performance comes before learning
graph$response_type <- factor(graph$response_type, levels = c("sum_performance", "sum_learning"))
ggplot(data = graph, aes(x = response_type, y = mean, fill = Condition)) +
geom_bar(stat = "identity", position = "dodge", width = 0.7, colour="black") +
geom_errorbar(aes(ymin = mean - sem, ymax = mean + sem), position = position_dodge(width = 0.7), width = 0.25) +
labs(title = "Parental Responses to Child-Failure Scenario",
x = "",
y = "Number of Responses",
fill = "",) +
scale_fill_manual(values = c("Debilitating" = "white", "Enhancing" = "darkgrey"), #rename labels and dedicate colors to conditoins
name = "Condition",
labels = c("Debilitating" = "Failure-is-Debilitating Condition", "Enhancing" = "Failure-is-Enhancing Condition")) +
scale_x_discrete(labels = c("sum_performance" = "Performance-Oriented", "sum_learning" = "Learning-Oriented")) +
scale_y_continuous(expand = c(0, 0)) + # plot starts at bottom of y-axis
theme_minimal() +
theme( # change theme to be more similar to original paper
panel.grid = element_blank(),
panel.border = element_blank(),
axis.line = element_line(color = "black"),
)
graph <- coded_data %>%
pivot_longer(sum_performance:sum_learning,
names_to = "response_type",
values_to = "num_response") %>%
group_by(Condition, response_type) %>%
summarise(
count = n(),
mean = mean(num_response, na.rm = TRUE),
sd = sd(num_response, na.rm = TRUE),
sem = sd / sqrt(count),
.groups = "drop"
)
head(graph)
### Reorder the bars so that performance comes before learning
graph$response_type <- factor(graph$response_type, levels = c("sum_performance", "sum_learning"))
ggplot(data = graph, aes(x = response_type, y = mean, fill = Condition)) +
geom_bar(stat = "identity", position = "dodge", width = 0.7, colour="black") +
geom_errorbar(aes(ymin = mean - sem, ymax = mean + sem), position = position_dodge(width = 0.7), width = 0.25) +
labs(title = "Parental Responses to Child-Failure Scenario",
x = "",
y = "Number of Responses",
fill = "",) +
scale_fill_manual(values = c("Debilitating" = "white", "Enhancing" = "darkgrey"), #rename labels and dedicate colors to conditoins
name = "Condition",
labels = c("Debilitating" = "Failure-is-Debilitating Condition", "Enhancing" = "Failure-is-Enhancing Condition")) +
scale_x_discrete(labels = c("sum_performance" = "Performance-Oriented", "sum_learning" = "Learning-Oriented")) +
scale_y_continuous(expand = c(0, 0)) + # plot starts at bottom of y-axis
theme_minimal() +
theme( # change theme to be more similar to original paper
panel.grid = element_blank(),
panel.border = element_blank(),
axis.line = element_line(color = "black"),
)
graph <- coded_data %>%
pivot_longer(sum_performance:sum_learning,
names_to = "response_type",
values_to = "num_response") %>%
group_by(Condition, response_type) %>%
summarise(
count = n(),
mean = mean(num_response, na.rm = TRUE),
sd = sd(num_response, na.rm = TRUE),
sem = sd / sqrt(count),
.groups = "drop"
)
head(graph)
### Reorder the bars so that performance comes before learning
graph$response_type <- factor(graph$response_type, levels = c("sum_performance", "sum_learning"))
ggplot(data = graph, aes(x = response_type, y = mean, fill = Condition)) +
geom_bar(stat = "identity", position = "dodge", width = 0.7, colour="black") +
geom_errorbar(aes(ymin = mean - sem, ymax = mean + sem), position = position_dodge(width = 0.7), width = 0.25) +
labs(title = "Parental Responses to Child-Failure Scenario",
x = "",
y = "Number of Responses",
fill = "",) +
scale_fill_manual(values = c("Debilitating" = "white", "Enhancing" = "darkgrey"), #rename labels and dedicate colors to conditoins
name = "Condition",
labels = c("Debilitating" = "Failure-is-Debilitating Condition", "Enhancing" = "Failure-is-Enhancing Condition")) +
scale_x_discrete(labels = c("sum_performance" = "Performance-Oriented", "sum_learning" = "Learning-Oriented")) +
scale_y_continuous(expand = c(0, 0)) + # plot starts at bottom of y-axis
theme_minimal() +
theme( # change theme to be more similar to original paper
panel.grid = element_blank(),
panel.border = element_blank(),
axis.line = element_line(color = "black"),
)
head(graph)
